<!doctype html><html lang=zh-CN><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=robots content="noodp"><title>自然语言处理 - J-shiro's Blog</title><meta name=Description content="Hugo theme - LoveIt"><meta property="og:url" content="https://j-shiro.github.io/nlp_note/">
<meta property="og:site_name" content="J-shiro's Blog"><meta property="og:title" content="自然语言处理"><meta property="og:description" content="自然语言处理，Natural language processing (NLP) ，有监督学习
序列模型 文本是一种序列数据，一句话是由一个个按顺序排列的单词组成的
数据表示
$X^{(i)} = [x_1^{(i)}, x_2^{(i)}, \dots, x_{T_x^{(i)}}^{(i)}]$： 第 $i$ 个样本的输入序列，有 $T_x^{(i)}$ 个元素（单词/字符等）"><meta property="og:locale" content="zh_CN"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2024-10-12T00:00:00+00:00"><meta property="article:modified_time" content="2025-05-26T23:55:37+08:00"><meta property="article:tag" content="NLP"><meta property="og:image" content="https://j-shiro.github.io/logo.png"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://j-shiro.github.io/logo.png"><meta name=twitter:title content="自然语言处理"><meta name=twitter:description content="自然语言处理，Natural language processing (NLP) ，有监督学习
序列模型 文本是一种序列数据，一句话是由一个个按顺序排列的单词组成的
数据表示
$X^{(i)} = [x_1^{(i)}, x_2^{(i)}, \dots, x_{T_x^{(i)}}^{(i)}]$： 第 $i$ 个样本的输入序列，有 $T_x^{(i)}$ 个元素（单词/字符等）"><meta name=application-name content="LoveIt"><meta name=apple-mobile-web-app-title content="LoveIt"><meta name=referrer content="no-referrer"><meta name=theme-color content="#ffffff"><meta name=msapplication-TileColor content="#da532c"><link rel="shortcut icon" type=image/x-icon href=/favicon.ico><link rel=icon type=image/png sizes=32x32 href=/favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=/favicon-16x16.png><link rel=apple-touch-icon sizes=180x180 href=/apple-touch-icon.png><link rel=mask-icon href=/safari-pinned-tab.svg color=#5bbad5><link rel=manifest href=/site.webmanifest><link rel=canonical href=https://j-shiro.github.io/nlp_note/><link rel=prev href=https://j-shiro.github.io/linux_note/><link rel=next href=https://j-shiro.github.io/deep_learning_note/><link rel=stylesheet href=/css/style.min.css><link rel=preload href=https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.7.2/css/all.min.css as=style onload='this.onload=null,this.rel="stylesheet"'><noscript><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.7.2/css/all.min.css></noscript><link rel=preload href=https://cdn.jsdelivr.net/npm/animate.css@4.1.1/animate.min.css as=style onload='this.onload=null,this.rel="stylesheet"'><noscript><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/animate.css@4.1.1/animate.min.css></noscript><script type=application/ld+json>{"@context":"http://schema.org","@type":"BlogPosting","headline":"自然语言处理","inLanguage":"zh-CN","mainEntityOfPage":{"@type":"WebPage","@id":"https:\/\/j-shiro.github.io\/nlp_note\/"},"image":["https:\/\/j-shiro.github.io\/images\/Apple-Devices-Preview.png"],"genre":"posts","keywords":"NLP","wordcount":3180,"url":"https:\/\/j-shiro.github.io\/nlp_note\/","datePublished":"2024-10-12T00:00:00+00:00","dateModified":"2025-05-26T23:55:37+08:00","license":"This work is licensed under a Creative Commons Attribution-NonCommercial 4.0 International License.","publisher":{"@type":"Organization","name":"xxxx","logo":{"@type":"ImageObject","url":"https:\/\/j-shiro.github.io\/images\/avatar.png","width":800,"height":800}},"author":{"@type":"Person","name":"jshiro"},"description":""}</script></head><body data-header-desktop=fixed data-header-mobile=auto><script>(window.localStorage&&localStorage.getItem("theme")?localStorage.getItem("theme")==="dark":"auto"==="auto"?window.matchMedia("(prefers-color-scheme: dark)").matches:"auto"==="dark")&&document.body.setAttribute("theme","dark")</script><div id=mask></div><div class=wrapper><header class=desktop id=header-desktop><div class=header-wrapper><div class=header-title><a href=/ title="J-shiro's Blog"><span class=header-title-pre><i class='far fa-kiss-wink-heart fa-fw' aria-hidden=true></i></span>LoveIt</a></div><div class=menu><div class=menu-inner><a class=menu-item href=/posts/>所有文章 </a><a class=menu-item href=/tags/>标签 </a><a class=menu-item href=/categories/>分类 </a><a class=menu-item href=/categories/documentation/>文档 </a><a class=menu-item href=/about/>关于 </a><a class=menu-item href=https://github.com/dillonzq/LoveIt title=GitHub rel="noopener noreffer" target=_blank><i class='fab fa-github fa-fw' aria-hidden=true></i> </a><span class="menu-item delimiter"></span><span class="menu-item search" id=search-desktop>
<input type=text placeholder=搜索文章标题或内容... id=search-input-desktop>
<a href=javascript:void(0); class="search-button search-toggle" id=search-toggle-desktop title=搜索><i class="fas fa-search fa-fw" aria-hidden=true></i>
</a><a href=javascript:void(0); class="search-button search-clear" id=search-clear-desktop title=清空><i class="fas fa-times-circle fa-fw" aria-hidden=true></i>
</a><span class="search-button search-loading" id=search-loading-desktop><i class="fas fa-spinner fa-fw fa-spin" aria-hidden=true></i>
</span></span><a href=javascript:void(0); class="menu-item theme-switch" title=切换主题><i class="fas fa-adjust fa-fw" aria-hidden=true></i>
</a><a href=javascript:void(0); class="menu-item language" title=选择语言><i class="fa fa-globe fa-fw" aria-hidden=true></i>
<select class=language-select id=language-select-desktop onchange="location=this.value"><option value=/nlp_note/ selected>简体中文</option></select></a></div></div></div></header><header class=mobile id=header-mobile><div class=header-container><div class=header-wrapper><div class=header-title><a href=/ title="J-shiro's Blog"><span class=header-title-pre><i class='far fa-kiss-wink-heart fa-fw' aria-hidden=true></i></span>LoveIt</a></div><div class=menu-toggle id=menu-toggle-mobile><span></span><span></span><span></span></div></div><div class=menu id=menu-mobile><div class=search-wrapper><div class="search mobile" id=search-mobile><input type=text placeholder=搜索文章标题或内容... id=search-input-mobile>
<a href=javascript:void(0); class="search-button search-toggle" id=search-toggle-mobile title=搜索><i class="fas fa-search fa-fw" aria-hidden=true></i>
</a><a href=javascript:void(0); class="search-button search-clear" id=search-clear-mobile title=清空><i class="fas fa-times-circle fa-fw" aria-hidden=true></i>
</a><span class="search-button search-loading" id=search-loading-mobile><i class="fas fa-spinner fa-fw fa-spin" aria-hidden=true></i></span></div><a href=javascript:void(0); class=search-cancel id=search-cancel-mobile>取消</a></div><a class=menu-item href=/posts/ title>所有文章</a><a class=menu-item href=/tags/ title>标签</a><a class=menu-item href=/categories/ title>分类</a><a class=menu-item href=/categories/documentation/ title>文档</a><a class=menu-item href=/about/ title>关于</a><a class=menu-item href=https://github.com/dillonzq/LoveIt title=GitHub rel="noopener noreffer" target=_blank><i class='fab fa-github fa-fw' aria-hidden=true></i></a><a href=javascript:void(0); class="menu-item theme-switch" title=切换主题>
<i class="fas fa-adjust fa-fw" aria-hidden=true></i>
</a><a href=javascript:void(0); class=menu-item title=选择语言><i class="fa fa-globe fa-fw" aria-hidden=true></i>
<select class=language-select onchange="location=this.value"><option value=/nlp_note/ selected>简体中文</option></select></a></div></div></header><div class="search-dropdown desktop"><div id=search-dropdown-desktop></div></div><div class="search-dropdown mobile"><div id=search-dropdown-mobile></div></div><main class=main><div class=container><div class=toc id=toc-auto><h2 class=toc-title>目录</h2><div class=toc-content id=toc-content-auto></div></div><article class="page single"><h1 class="single-title animate__animated animate__flipInX">自然语言处理</h1><div class=post-meta><div class=post-meta-line><span class=post-author><a href=/ title=Author rel=author class=author><i class="fas fa-user-circle fa-fw" aria-hidden=true></i>jshiro</a></span>&nbsp;<span class=post-category>收录于 <a href=/categories/notes/><i class="far fa-folder fa-fw" aria-hidden=true></i>Notes</a>&nbsp;<a href=/categories/ai/><i class="far fa-folder fa-fw" aria-hidden=true></i>AI</a></span></div><div class=post-meta-line><i class="far fa-calendar-alt fa-fw" aria-hidden=true></i>&nbsp;<time datetime=2024-10-12>2024-10-12</time>&nbsp;<i class="fas fa-pencil-alt fa-fw" aria-hidden=true></i>&nbsp;约 3180 字&nbsp;
<i class="far fa-clock fa-fw" aria-hidden=true></i>&nbsp;预计阅读 7 分钟&nbsp;<span id=/nlp_note/ class=leancloud_visitors data-flag-title=自然语言处理>
<i class="far fa-eye fa-fw" aria-hidden=true></i>&nbsp;<span class=leancloud-visitors-count></span>&nbsp;次阅读
</span>&nbsp;</div></div><div class="details toc" id=toc-static data-kept><div class="details-summary toc-title"><span>目录</span>
<span><i class="details-icon fas fa-angle-right" aria-hidden=true></i></span></div><div class="details-content toc-content" id=toc-content-static><nav id=TableOfContents><ul><li><ul><li><a href=#序列模型>序列模型</a></li><li><a href=#循环神经网络>循环神经网络</a></li><li><a href=#词嵌入模型>词嵌入模型</a></li><li><a href=#词向量模型>词向量模型</a><ul><li><a href=#word2vec>Word2Vec</a></li><li><a href=#skip-gram>Skip-gram</a></li><li><a href=#glove>GloVe</a></li></ul></li><li><a href=#seq2seq模型>Seq2Seq模型</a><ul><li><a href=#定向搜索>定向搜索</a></li><li><a href=#注意力模型>注意力模型</a></li></ul></li><li><a href=#transformer>Transformer</a></li></ul></li></ul></nav></div></div><div class=content id=content><p>自然语言处理，Natural language processing (NLP) ，有监督学习</p><h3 id=序列模型>序列模型</h3><p>文本是一种<strong>序列数据</strong>，一句话是由一个个按顺序排列的单词组成的</p><p><strong>数据表示</strong></p><ul><li><p>$X^{(i)} = [x_1^{(i)}, x_2^{(i)}, \dots, x_{T_x^{(i)}}^{(i)}]$： 第 $i$ 个样本的输入序列，有 $T_x^{(i)}$ 个元素（单词/字符等）</p></li><li><p>$Y^{(i)} = [y_1^{(i)}, y_2^{(i)}, \dots, y_{T_y^{(i)}}^{(i)}]$：第 $i$ 个样本的输出序列</p></li><li><p>$T_x^{(i)}$表示第 i 个训练样例的序列长度，$X^{(i)}$表示 i 序列中第 t 个元素</p></li></ul><p><strong>One-Hot 编码</strong></p><ul><li><p>存在单词字典列表，即每个单词对应一个等长向量列表，向量长度为词汇表大小 $|V|$</p></li><li><p>对应单词索引处为1其余为0</p></li></ul><p><strong>类别</strong>：RNN循环神经网络、LSTM长短期记忆网络、GRU门控循环单元、Transformer注意力机制核心</p><h3 id=循环神经网络>循环神经网络</h3><ul><li>Recurrent Neural，处理一维序列化数据</li><li>关键思想：<strong>时间步之间共享权重</strong>，保留一个<strong>隐藏状态 $a^{&lt;t>}$</strong>，表示前面序列的记忆</li></ul><p><strong>前向传播</strong></p><img src=/img/nlp_note.zh-cn.assets/172845431716878.png alt=图片无法加载><ol><li><p>初始隐藏状态：$a^{&lt;0>}=\vec 0$</p></li><li><p>更新隐藏状态（Tanh, ReLU）：$a^{&lt;t>}=g(w_{aa}a^{&lt;t-1>}+w_{ax}x^{&lt;t>}+b_a)$</p></li></ol><ul><li>整合，将$W_{aa}$和$W_{ax}$矩阵左右联结表示为$W_a$，2 式转化为</li><li>$a^{&lt;t>}=g(W_a[a^{&lt;t-1>}, x^{&lt;t>}]+b_a)$，[ , ]中表示上下联结</li></ul><ol start=3><li>输出预测（Sigmoid, SoftMax）： $\hat y^{&lt;t>}=g(w_{ya}a^{&lt;t>}+b_y)$</li></ol><p><strong>基于时间反向传播</strong></p><p>预测特定词是一个人名的概率是$\hat y$，使用逻辑回归损失</p><p>单个时间步损失：$L^{&lt;t>}(\hat y^{&lt;t>},y^{&lt;t>})=-y^{&lt;t>}\log \hat y^{&lt;t>}-(1-y^{&lt;t>})\log (1-\hat y^{&lt;t>})$</p><p>总体损失函数：$L(\hat y, y)=\sum_{t=1}^{T_y}L^{&lt;t>}(\hat y^{&lt;t>},y^{&lt;t>})$，$T_x$和$T_y$可能不同</p><p><strong>架构类型</strong></p><p><strong>一对一</strong>：图像分类等任务</p><p><strong>一对多</strong>：图像描述</p><p><strong>多对一</strong>：情感分类</p><p><strong>多对多（对齐）</strong>：命名实体识别（NER）</p><p><strong>多对多（非对齐）</strong>：机器翻译</p><img src=/img/nlp_note.zh-cn.assets/172845431716879.png alt=图片无法加载>
<img src=/img/nlp_note.zh-cn.assets/172845431716880.png alt=图片无法加载><p><strong>构建语言模型</strong></p><p>目标：学习一个序列中下一个词的<strong>条件概率</strong>：$P(x^{&lt;t>}|x^{&lt;1>}, x^{&lt;2>},\cdots, x^{<t-1>})$</p><p><strong>数据处理</strong></p><p>训练集为极大<strong>语料库</strong>（corpus），将数据句子<strong>标记化</strong>（tokenize），句子末尾加入<code>&lt;EOS></code>（End Of Sentence）标记，定位句子结尾，未知单词标记为<code>&lt;UNK></code>（unknown word）标记，$\hat y$ 对应于已知条件概率P(__|已知)</p><p><strong>损失函数</strong>：对于每个时间步，$L(\hat y^{&lt;t>},y^{&lt;t>})=-\sum_iy_i^{&lt;t>}\log \hat y_i^{&lt;t>}$，softmax损失函数</p><img src=/img/nlp_note.zh-cn.assets/172845431716881.png alt=图片无法加载><p><strong>Gate Recurrent Unit（GRU）门控制单元</strong></p><ul><li>解决RNN<strong>梯度消失问题，引入了</strong>门机制<strong>来控制信息流动</strong></li><li>$C^{&lt;t>}$记忆单元来存储记忆，如：需要记住cat是单数，使用was而不是were</li><li>$\tilde C^{&lt;t>}=\tanh (W_c[\Gamma_r\cdot C^{&lt;t-1>},x^{&lt;t>}]+b_c)$</li><li>门控值：<strong>更新门</strong>$\Gamma_u=\sigma(W_u[C^{&lt;t-1>},x^{&lt;t>}]+b_u)$，sigmoid使范围为0-1，为0表示不更新$C^{&lt;t>}$，同样适用于<strong>相关性门</strong>$\Gamma_r$</li><li>$C^{&lt;t>}=\Gamma_u\cdot \tilde C^{&lt;t>}+(1-\Gamma_u)\cdot C^{&lt;t-1>}$ ，a和c相等</li></ul><img src=/img/nlp_note.zh-cn.assets/172845431716882.png alt=图片无法加载><p><strong>Long Short Term Memory Units（LSTM）长短期记忆单元</strong></p><ul><li>$\tilde C^{&lt;t>}=\tanh (W_c[a^{&lt;t-1>},x^{&lt;t>}]+b_c)$</li><li><strong>更新门</strong>$\Gamma_u=\sigma(W_u[C^{&lt;t-1>},x^{&lt;t>}]+b_u)$，<strong>遗忘门</strong>$\Gamma_f=\sigma(W_f[C^{&lt;t-1>},x^{&lt;t>}]+b_f)$，<strong>输出门</strong>$\Gamma_o=\sigma(W_o[C^{&lt;t-1>},x^{&lt;t>}]+b_o)$</li><li>更新：$C^{&lt;t>}=\Gamma_u\cdot \tilde C^{&lt;t>}+\Gamma_f\cdot C^{&lt;t-1>}$，$a^{&lt;t>}=\Gamma_o\cdot C^{&lt;t>}$，a和c不再相等</li></ul><img src=/img/nlp_note.zh-cn.assets/172845431716883.png alt=图片无法加载><p><strong>情感分类</strong></p><img src=/img/nlp_note.zh-cn.assets/172845431716884.png alt=图片无法加载><p><strong>双向递归网络</strong></p><ul><li>（bi-directional recurrent neural network, BRNNs）</li><li>解决单词不能单从前面得出是否是人名</li></ul><img src=/img/nlp_note.zh-cn.assets/172845431716885.png alt=图片无法加载><p><strong>深度递归网络</strong></p><ul><li>Deep RNNs</li></ul><img src=/img/nlp_note.zh-cn.assets/172845431716886.png alt=图片无法加载><h3 id=词嵌入模型>词嵌入模型</h3><p>将文字或词语转换为一系列数字，通常是一个向量。词嵌入类似一个为每个词分配的数字列表，这些数字不随机，而是捕获了这个词的含义和它在文本中的上下文，使得语义上相似或相关的词在数字空间中比较接近</p><p><strong>词向量表示</strong></p><ul><li>one-hot编码两两单词相乘为0</li><li>需要描述一个物，需要综合多项指标（向量），向量可以用不同方法计算相似度，相似词在特征表达中比较相似</li><li>特征比如单词与性别（<code>-1~1</code>）、年龄、是否为食物的指标值（<code>0~1</code>）</li></ul><p><strong>词向量相似性</strong></p><p>1️⃣ 类比推理</p><p>$e_{king}-e_{man}+e_{woman} \approx e_{queen}$</p><p>2️⃣ <strong>欧氏距离</strong></p><p>衡量向量在几何空间的绝对距离：$d(u, v) = \sqrt{\sum_i(u_i-v_i)^2}$</p><p>3️⃣ <strong>余弦相似度(相似函数)</strong></p><ul><li>$\arg \max sim(e_w,e_{king}-e_{man}+e_{woman})$</li><li>$sim(u,v)=\frac{u^Tv}{||u||_2\cdot||v||_2}$</li><li>实则求 u 和 v 之间的角$\phi$的余弦值，<code>0~180:1~-1</code></li></ul><p><strong>矩阵嵌入</strong></p><p>使用单词矩阵与one-hot编码向量相乘获取对应单词的向量，实则一般在<strong>嵌入层</strong>中直接取对应列即可</p><img src=/img/nlp_note.zh-cn.assets/image-20241012233656947.png alt=图片无法加载><h3 id=词向量模型>词向量模型</h3><h4 id=word2vec>Word2Vec</h4><p>Word2Vec 将单词嵌入空间中，通过上下文预测目标词或反向预测上下文</p><p><strong>训练数据</strong></p><img src=/img/nlp_note.zh-cn.assets/172845431716887.png alt=图片无法加载><p>两种结构：<strong>CBOW（上下文推词）</strong> 与 <strong>Skipgram（词推上下文）</strong></p><img src=/img/nlp_note.zh-cn.assets/172845431716888.png alt=图片无法加载><p><strong>除偏（性别、种族偏差）</strong></p><ol><li>识别需要消除的偏差方向，使用$e_{he}-e_{she}$等多组的平均值获取坐标轴</li><li>中立化：未被定义的词通过映射到避开偏差</li><li>均匀化：移动相关性别的词使得距离坐标轴相等</li></ol><img src=/img/nlp_note.zh-cn.assets/172845431716989.png alt=图片无法加载><h4 id=skip-gram>Skip-gram</h4><ul><li><strong>有监督学习</strong></li><li><strong>目标</strong>：给定上下文语境词 c，预测目标词 t ，$\theta_t$ 是关于 t 的参数，未包含偏置项</li></ul><p><strong>Softmax</strong> 概率函数：分母的运算代价极大</p><p>$p(t|c)=\frac{e^{\theta_t^Te_c}}{\sum_{j=1}^{10000}e^{\theta_j^Te_c}}$</p><p><strong>负采样（Negative Sampling）</strong></p><p>用 k 个词进行训练，其中：</p><ul><li>1 个正样本（真实上下文词对）</li><li>$k-1$ 个负样本（随机采样，不应出现在该上下文中）</li></ul><p>使用 <strong>logistic 回归</strong>做二分类训练，使得正样本概率高、负样本概率低：</p><img src=/img/nlp_note.zh-cn.assets/image-20250526233624704.png alt=图片无法加载><h4 id=glove>GloVe</h4><ul><li><p>Global Vectors for word representation，基于共现矩阵$X_{ij}$：词 i 和词 j 共同出现概率</p></li><li><p>$f(X_{ij})$是权重项，调整使得常见词权重不高，罕见词权重不低，X为0时f为0，采用"0log0=0"的规则</p></li><li><p>目标函数：带权重的平方损失</p><ul><li>$minimize,, \sum_{i=1}^{10000}\sum_{j=1}^{10000}f(X_{ij})(\theta_i^Te_j+b_i+b_j&rsquo;-\log X_{ij})^2$</li><li>随机均匀初始化 $\theta,e$，梯度下降最小化目标函数</li></ul></li><li><p>最终词向量：$e_w^{(final)}=\frac{e_w+\theta_w}{2}$</p></li></ul><h3 id=seq2seq模型>Seq2Seq模型</h3><ul><li>（Sequence-to-sequence），机器翻译+语音识别</li><li>结构由两个 RNN（或LSTM/GRU）组成：<ul><li>编码器 Encoder：将输入句子编码成上下文向量</li><li>解码器 Decoder：逐步生成输出序列</li></ul></li><li>先将语言经过编码器，然后经过解码器进行翻译，计算$P(y^{&lt;1>}|x)$</li></ul><img src=/img/nlp_note.zh-cn.assets/172845431716990.png alt=图片无法加载><h4 id=定向搜索>定向搜索</h4><ul><li>Beam Search或集束搜索</li><li>参数B表示集束宽度，保留备选单词数，每次选择B个最高条件概率词元</li><li>$\arg \max_y\frac{1}{T_y^{\alpha}}\sum_{t=1}^{T_y}\log P(y^{&lt;t>}|x,y^{&lt;1>},\cdots ,y^{&lt;t-1>})$，$\alpha$=0.7取部分规范化</li><li>$P(y^{&lt;1>}\cdots y^{&lt;T_y>}|x)=P(y^{&lt;1>}|x)P(y^{&lt;2>}|x,y^{&lt;1>})\cdots P(y^{&lt;T_y>}|x,y^{&lt;1>},\cdots ,y^{&lt;T_y-1>})$</li></ul><img src=/img/nlp_note.zh-cn.assets/172845431716991.png alt=图片无法加载><p><strong>Bleu指数</strong></p><ul><li>多个好结果下选择一个最好的看n元单词在参考翻译中出现概率</li><li>$P_n=\frac{\sum_{n-grams\in \hat y}Count_{clips}(n-gram)}{\sum_{n-grams\in \hat y}Count(n-gram)}$再去各个n的平均值</li><li>n个n个取参考翻译记录每n个单词的count，再在机器翻译中得出count_clip</li><li>Bleu指数在句子长度小和极大时都很小</li></ul><h4 id=注意力模型>注意力模型</h4><p>（attention model），会生成多个注意力权重参数$\alpha$总和为1，将在某个词放入多少注意力，$\alpha^{&lt;t, t&rsquo;>}$ 表示生成 t 时需要对 t&rsquo; 花费的注意力是多少</p><img src=/img/nlp_note.zh-cn.assets/172845431716992.png alt=图片无法加载><h3 id=transformer>Transformer</h3><p>同一时间对一句话同时处理，注意力+卷积</p><p><strong>自注意力机制：并行计算</strong></p><p>为每个单词计算出一个基于注意力的表达：$A(q,K,V)$，即$A^{&lt;1>},A^{&lt;2>},\cdot$</p><img src=/img/nlp_note.zh-cn.assets/172845431716993.png alt=图片无法加载><p>将每个单词与q(Query), K(Key), V(Value)关联，W为学习参数</p><ol><li>$q^{&lt;i>}=W^Q\cdot x^{&lt;i>}$</li><li>$K^{&lt;i>}=W^K\cdot x^{&lt;i>}$</li><li>$V^{&lt;i>}=W^V\cdot x^{&lt;i>}$</li></ol><img src=/img/nlp_note.zh-cn.assets/172845431716994.png alt=图片无法加载><p><strong>多头注意力机制：循环并行计算自注意力</strong></p><p>通过不同矩阵参数集进行重复多次的自注意力计算，用于回答不同问题：when,where,who,how&mldr;</p><p><strong>transformer架构</strong></p><img src=/img/nlp_note.zh-cn.assets/172845431716995.png alt=图片无法加载></div><div class=post-footer id=post-footer><div class=post-info><div class=post-info-line><div class=post-info-mod><span>更新于 2025-05-26&nbsp;<a class=git-hash href=https://github.com/dillonzq/LoveIt/commit/640a6227cca5bdfb3aad8bca4ae23c0050336955 target=_blank title="commit by J-shiro(541737231@qq.com) 640a6227cca5bdfb3aad8bca4ae23c0050336955: add nlp note">
<i class="fas fa-hashtag fa-fw" aria-hidden=true></i>640a622</a></span></div></div><div class=post-info-line><div class=post-info-md><span><a class=link-to-markdown href=/nlp_note/index.md target=_blank>阅读原始文档</a></span></div><div class=post-info-share><span><a href=javascript:void(0); title="分享到 Facebook" data-sharer=facebook data-url=https://j-shiro.github.io/nlp_note/ data-hashtag=NLP><i class="fab fa-facebook-square fa-fw" aria-hidden=true></i></a><a href=javascript:void(0); title="分享到 Line" data-sharer=line data-url=https://j-shiro.github.io/nlp_note/ data-title=自然语言处理><i data-svg-src=https://cdn.jsdelivr.net/npm/simple-icons@14.9.0/icons/line.svg aria-hidden=true></i></a><a href=javascript:void(0); title="分享到 微博" data-sharer=weibo data-url=https://j-shiro.github.io/nlp_note/ data-title=自然语言处理><i class="fab fa-weibo fa-fw" aria-hidden=true></i></a><a href="https://t.me/share/url?url=https%3a%2f%2fj-shiro.github.io%2fnlp_note%2f&amp;text=%e8%87%aa%e7%84%b6%e8%af%ad%e8%a8%80%e5%a4%84%e7%90%86" target=_blank title="分享到 Telegram"><i class="fab fa-telegram fa-fw" aria-hidden=true></i></a></span></div></div></div><div class=post-info-more><section class=post-tags><i class="fas fa-tags fa-fw" aria-hidden=true></i>&nbsp;<a href=/tags/nlp/>NLP</a></section><section><span><a href=javascript:void(0); onclick=window.history.back()>返回</a></span>&nbsp;|&nbsp;<span><a href=/>主页</a></span></section></div><div class=post-nav><a href=/linux_note/ class=prev rel=prev title=LINUX><i class="fas fa-angle-left fa-fw" aria-hidden=true></i>LINUX</a>
<a href=/deep_learning_note/ class=next rel=next title=深度学习>深度学习<i class="fas fa-angle-right fa-fw" aria-hidden=true></i></a></div></div><div id=comments><div id=valine class=comment></div><noscript>Please enable JavaScript to view the comments powered by <a href=https://valine.js.org/>Valine</a>.</noscript></div></article></div></main><footer class=footer><div class=footer-container><div class=footer-line>由 <a href=https://gohugo.io/ target=_blank rel="noopener noreffer" title="Hugo 0.143.1">Hugo</a> 强力驱动 | 主题 - <a href=https://github.com/dillonzq/LoveIt target=_blank rel="noopener noreffer" title="LoveIt 0.3.1-DEV"><i class="far fa-kiss-wink-heart fa-fw" aria-hidden=true></i> LoveIt</a></div><div class=footer-line itemscope itemtype=http://schema.org/CreativeWork><i class="far fa-copyright fa-fw" aria-hidden=true></i><span itemprop=copyrightYear>2019 - 2025</span><span class=author itemprop=copyrightHolder>&nbsp;<a href=/ target=_blank>jshiro</a></span>&nbsp;|&nbsp;<span class=license><a rel="license external nofollow noopener noreffer" href=https://creativecommons.org/licenses/by-nc/4.0/ target=_blank>CC BY-NC 4.0</a></span></div></div></footer></div><div id=fixed-buttons><a href=# id=back-to-top class=fixed-button title=回到顶部><i class="fas fa-arrow-up fa-fw" aria-hidden=true></i></a></div><div id=fixed-buttons-hidden><a href=# id=view-comments class=fixed-button title=查看评论><i class="fas fa-comment fa-fw" aria-hidden=true></i></a></div><link rel=stylesheet href=/lib/valine/valine.min.css><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.16.21/dist/katex.min.css><script src=https://cdn.jsdelivr.net/npm/valine@1.5.3/dist/Valine.min.js></script><script src=https://cdn.jsdelivr.net/npm/autocomplete.js@0.38.1/dist/autocomplete.min.js></script><script src=https://cdn.jsdelivr.net/npm/algoliasearch@5.20.2/dist/lite/builds/browser.umd.min.js></script><script src=https://cdn.jsdelivr.net/npm/lazysizes@5.3.2/lazysizes.min.js></script><script src=https://cdn.jsdelivr.net/npm/clipboard@2.0.11/dist/clipboard.min.js></script><script src=https://cdn.jsdelivr.net/npm/sharer.js@0.5.2/sharer.min.js></script><script src=https://cdn.jsdelivr.net/npm/katex@0.16.21/dist/katex.min.js></script><script src=https://cdn.jsdelivr.net/npm/katex@0.16.21/dist/contrib/auto-render.min.js></script><script src=https://cdn.jsdelivr.net/npm/katex@0.16.21/dist/contrib/copy-tex.min.js></script><script src=https://cdn.jsdelivr.net/npm/katex@0.16.21/dist/contrib/mhchem.min.js></script><script>window.config={comment:{valine:{appId:"wAgpK3Sa13Vfm247ncxiGVDA-MdYXbMMI",appKey:"p6X9gNaJTGB1sqgG9ZnrEwy4",avatar:"mp",el:"#valine",emojiCDN:"https://cdn.jsdelivr.net/npm/emoji-datasource-google@15.1.2/img/google/64/",emojiMaps:{100:"1f4af.png",alien:"1f47d.png",anger:"1f4a2.png",angry:"1f620.png",anguished:"1f627.png",astonished:"1f632.png",black_heart:"1f5a4.png",blue_heart:"1f499.png",blush:"1f60a.png",bomb:"1f4a3.png",boom:"1f4a5.png",broken_heart:"1f494.png",brown_heart:"1f90e.png",clown_face:"1f921.png",cold_face:"1f976.png",cold_sweat:"1f630.png",confounded:"1f616.png",confused:"1f615.png",cry:"1f622.png",crying_cat_face:"1f63f.png",cupid:"1f498.png",dash:"1f4a8.png",disappointed:"1f61e.png",disappointed_relieved:"1f625.png",dizzy:"1f4ab.png",dizzy_face:"1f635.png",drooling_face:"1f924.png",exploding_head:"1f92f.png",expressionless:"1f611.png",face_vomiting:"1f92e.png",face_with_cowboy_hat:"1f920.png",face_with_hand_over_mouth:"1f92d.png",face_with_head_bandage:"1f915.png",face_with_monocle:"1f9d0.png",face_with_raised_eyebrow:"1f928.png",face_with_rolling_eyes:"1f644.png",face_with_symbols_on_mouth:"1f92c.png",face_with_thermometer:"1f912.png",fearful:"1f628.png",flushed:"1f633.png",frowning:"1f626.png",ghost:"1f47b.png",gift_heart:"1f49d.png",green_heart:"1f49a.png",grimacing:"1f62c.png",grin:"1f601.png",grinning:"1f600.png",hankey:"1f4a9.png",hear_no_evil:"1f649.png",heart:"2764-fe0f.png",heart_decoration:"1f49f.png",heart_eyes:"1f60d.png",heart_eyes_cat:"1f63b.png",heartbeat:"1f493.png",heartpulse:"1f497.png",heavy_heart_exclamation_mark_ornament:"2763-fe0f.png",hole:"1f573-fe0f.png",hot_face:"1f975.png",hugging_face:"1f917.png",hushed:"1f62f.png",imp:"1f47f.png",innocent:"1f607.png",japanese_goblin:"1f47a.png",japanese_ogre:"1f479.png",joy:"1f602.png",joy_cat:"1f639.png",kiss:"1f48b.png",kissing:"1f617.png",kissing_cat:"1f63d.png",kissing_closed_eyes:"1f61a.png",kissing_heart:"1f618.png",kissing_smiling_eyes:"1f619.png",laughing:"1f606.png",left_speech_bubble:"1f5e8-fe0f.png",love_letter:"1f48c.png",lying_face:"1f925.png",mask:"1f637.png",money_mouth_face:"1f911.png",nauseated_face:"1f922.png",nerd_face:"1f913.png",neutral_face:"1f610.png",no_mouth:"1f636.png",open_mouth:"1f62e.png",orange_heart:"1f9e1.png",partying_face:"1f973.png",pensive:"1f614.png",persevere:"1f623.png",pleading_face:"1f97a.png",pouting_cat:"1f63e.png",purple_heart:"1f49c.png",rage:"1f621.png",relaxed:"263a-fe0f.png",relieved:"1f60c.png",revolving_hearts:"1f49e.png",right_anger_bubble:"1f5ef-fe0f.png",robot_face:"1f916.png",rolling_on_the_floor_laughing:"1f923.png",scream:"1f631.png",scream_cat:"1f640.png",see_no_evil:"1f648.png",shushing_face:"1f92b.png",skull:"1f480.png",skull_and_crossbones:"2620-fe0f.png",sleeping:"1f634.png",sleepy:"1f62a.png",slightly_frowning_face:"1f641.png",slightly_smiling_face:"1f642.png",smile:"1f604.png",smile_cat:"1f638.png",smiley:"1f603.png",smiley_cat:"1f63a.png",smiling_face_with_3_hearts:"1f970.png",smiling_imp:"1f608.png",smirk:"1f60f.png",smirk_cat:"1f63c.png",sneezing_face:"1f927.png",sob:"1f62d.png",space_invader:"1f47e.png",sparkling_heart:"1f496.png",speak_no_evil:"1f64a.png",speech_balloon:"1f4ac.png","star-struck":"1f929.png",stuck_out_tongue:"1f61b.png",stuck_out_tongue_closed_eyes:"1f61d.png",stuck_out_tongue_winking_eye:"1f61c.png",sunglasses:"1f60e.png",sweat:"1f613.png",sweat_drops:"1f4a6.png",sweat_smile:"1f605.png",thinking_face:"1f914.png",thought_balloon:"1f4ad.png",tired_face:"1f62b.png",triumph:"1f624.png",two_hearts:"1f495.png",unamused:"1f612.png",upside_down_face:"1f643.png",weary:"1f629.png",white_frowning_face:"2639-fe0f.png",white_heart:"1f90d.png",wink:"1f609.png",woozy_face:"1f974.png",worried:"1f61f.png",yawning_face:"1f971.png",yellow_heart:"1f49b.png",yum:"1f60b.png",zany_face:"1f92a.png",zipper_mouth_face:"1f910.png",zzz:"1f4a4.png"},enableQQ:!1,highlight:!0,lang:"zh-CN",pageSize:10,placeholder:"你的评论 ...",recordIP:!0,serverURLs:"https://wagpk3sa.api.lncldglobal.com",visitor:!0}},math:{delimiters:[{display:!0,left:"$$",right:"$$"},{display:!0,left:"\\[",right:"\\]"},{display:!0,left:"\\begin{equation}",right:"\\end{equation}"},{display:!0,left:"\\begin{equation*}",right:"\\end{equation*}"},{display:!0,left:"\\begin{align}",right:"\\end{align}"},{display:!0,left:"\\begin{align*}",right:"\\end{align*}"},{display:!0,left:"\\begin{alignat}",right:"\\end{alignat}"},{display:!0,left:"\\begin{alignat*}",right:"\\end{alignat*}"},{display:!0,left:"\\begin{gather}",right:"\\end{gather}"},{display:!0,left:"\\begin{CD}",right:"\\end{CD}"},{display:!1,left:"$",right:"$"},{display:!1,left:"\\(",right:"\\)"}],strict:!1},search:{algoliaAppID:"GZT24PWKNT",algoliaIndex:"index",algoliaSearchKey:"634ab679e825b815de2663de38908f9d",highlightTag:"em",maxResultLength:10,noResultsFound:"没有找到结果",snippetLength:50,type:"algolia"}}</script><script src=/js/theme.min.js></script></body></html>